#!/bin/bash

# This wrapper script will invoke greylag in parallel on our SGE cluster.

# This directory is assumed to be shared across all cluster nodes
SHAREDTMPDIR=/clusterfs/home/proteomics/tmp

# options passed to all greylag-chase invocations
greylag_options="-v"

# Divide this run into this many parts.  Currently, elapsed time seems to be
# minimized if this is 5-10% larger than the number of cluster nodes (?).
#PARTS=${GREYLAG_PARTS:-1300}
PARTS=${GREYLAG_PARTS:-3000}

# Make this many attempts to run greylag-chase on the cluster nodes, in case
# the jobs fail on the nodes for whatever reason.
RETRIES=10


p=`basename $0`

usage() {
    cat <<EOF 1>&2
usage: $p [-l] <greylag.conf> <ms2-file> [ <ms2-file>... ]

Process a set of ms2 files as specified by the given configuration file (which
must end in '.conf' and should probably be in the current directory).

If the '-l' flag is given, stdout and stderr will be redirected to a
corresponding '.log' file.

EOF
    exit 0
}

err() {
    echo 1>&2 "$(date '+%b %e %H:%M:%S') $p: $@"
}

die() {
    err "$@"
    touch "$jobname.done-failed" || err "touch failed"
    exit 1
}

if [ "$1" == "-l" ]; then
    shift
    logging=1
fi

if [ $# -lt 2 ]; then
    usage
fi

config="$1"

rm -f ${config%.conf}.done-*

case "$config" in
    *.conf) true;;
    *) die "parameter filename must end in '*.conf'";;
esac

jobname=$(basename $config .conf)

shift
for f in "$@"; do
    if [ $(dirname $f) != "." ]; then
	die "file '$f' must be in the current working directory"
    fi
    case "$f" in
	*.ms2) true;;
	*) die "argument file '$f' should end in '.ms2'";;
    esac
done

[ -e $config ] || die "'$config' not found"

if ! ls -ld . | egrep -q '^drwxrws'; then
    chmod g+rwxs . || err "attempt to make this directory group writable failed"
fi


# Do some basic locking.  This tries to prevent simultaneous runs on the same
# parameter file, which would produce output to the same file, wasting
# resources and causing confusion.

lockfile="$jobname.lock"
trap "rm -f $lockfile" EXIT
ln -s $$ $lockfile 2>/dev/null || true
lockpid=$(ls -ld $lockfile | sed -e 's/^.*> //')

if [ $lockpid != $$ ]; then
    trap - EXIT			# leave lockfile
    die "this directory locked by another process (pid = $lockpid)?
         remove $lockfile if not"
fi

# point of no return
if [ "$logging" == "1" ]; then
    exec < /dev/null > "$jobname.log" 2>&1
fi

# priority?

# Be very careful with quoting, as these names may eventually come from
# Windows users...

shared_d=$SHAREDTMPDIR/greylag-$(date +%s)-$$ # unique

# Could add removal of the shared directory to the EXIT trap, but probably we
# shouldn't because pdq (and maybe SGE) may react badly
#    trap "rm -rf $lockfile $shared_d &" EXIT

mkdir $shared_d || die "'mkdir $shared_d' failed!"

cp -p "$config" $shared_d/ || die "config cp failed!"

err setting up work directory $shared_d
err recreating indices if necessary
for f in "$@"; do
    idx="$f.idx"
    if ! [ -e "$idx" -a "$idx" -nt "$f" ]; then
	greylag-index-spectra "$f" \
	    || die "greylag-index-spectra failed"
    fi
    cp -p "$f" "$idx" $shared_d/ || die "ms2/idx cp failed"
done

jobbasedir=$(basename $PWD)

#########################################################################
# submit the job in this shared directory so that the nodes can see it
pushd $shared_d > /dev/null || die "pushd failed!"

# use err

#cat <<EOF
#job name: $jobname
#shared dir: $shared_d
#config: $config
#ms2: $@
#EOF
#ls -l $shared_d/


err commence search

# It's important that the same ms2 arguments be given (in the same order) each
# time.

done_count=0
for ((try=1; try <= $RETRIES; try++)); do
    err try $try, $((PARTS - done_count)) parts left
    qsub -sync y -r y -b y -S /bin/bash -cwd -V -hard -l virtual_free=100M \
	-q greylag.q \
	-t 1-$PARTS \
	-N "greylag-$jobbasedir-$jobname-$$" \
	-e 'chase.$TASK_ID.err' \
	-o 'chase.$TASK_ID.out' \
	greylag-chase $greylag_options \
	--work-slice '$(greylag-sge-slice ${SGE_TASK_ID} ${SGE_TASK_LAST})' \
	--skip-if-done \
	"$config" "$@"
    qsub_status=$?
    cat $(find . -name 'chase-*.out' -o -name 'chase-*.err' | sort -t . -k 2n,3) /dev/null
    done_count=$(find . -name '*.glw' | wc -l)
    if [ $done_count = $PARTS ]; then
	break
    fi
done

if [ "$qsub_status" != 0 ]; then
    die "qsub of chase on nodes failed"
fi

if [ $done_count != $PARTS ]; then
    die "SGE/chase on nodes failed"
fi

popd > /dev/null || die "popd failed!"
#########################################################################

# now merge results (on master, for now)

err merge results

find $shared_d -name '*.glw' | greylag-merge --files-on-stdin "$jobname.glw" \
    || die "merge failed"

err write sqt files

greylag-sqt "$jobname.glw" || die "sqt write failed"

# for now, don't do this
#rm -fr "$shared_d" $lockfile

err complete
touch "$jobname.done-ok" || err "touch failed"
exit 0
