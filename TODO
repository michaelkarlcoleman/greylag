GREYLAG TODO LIST						-*-outline-*-


==============================================================================

OVERALL GOALS

1.  Replace SEQUEST at SIMR with something at least as good.
2.  Do better than SEQUEST for things that SIMR cares about.
3.  Showcase Python w/C-ish inner loop code implementation strategy.
4.  Try to take the best ideas from other similar programs.
5.  Greylag as a pedagogical artifact and foundation for further
    experimentation.

==============================================================================


MILESTONE M1:

* Good first impression
* Basic correctness
* Handles at least LCQ input
* Handles nonspecific cleavage
* Generates SQT output, usable in our pipeline, at least for non-N15 runs
* Decent performance/efficiency on our clusters

MILESTONE M2:

* Handles tryptic/etc cleavage
* Basic N15 handling
* Basic public website/source release/git archive
* Documentation (asciidoc/man pages)



TASK QUEUE

* SGE problems
** Avoid relying on SGE correctness/robustness?


* On processing large input file sets, the merge step requires huge RAM
** Fix by splitting into sets of N (8 or so)?

* greylag-validate/-merge/-sqt/-index should warn if no input files specified

* Look for (user-visible) changes that are easy to make now but harder later...

* Create basic documentation in reST format
** Need HTML (web and standalone), PDF?
*** index page (what is it?  why should you care?  links)
*** user guide
**** installation
**** cluster use
*** theory of operation document
**** basics of id search
**** explanation of greylag algorithm
**** greylag usage scenarios (solo, cluster)
**** how does MuDPIT work?
**** design choices, technology rationale (upsides/downsides)
** Makefile, install-to-web targets

* Test vs SEQUEST (MM?) on standard samples
** If SEQUEST better, why?

* Test no mod runs
** Status: looks a bit better on one run

* Test single mod runs
** Status: looks a bit better on one run

* Test multiple mod runs
** Status: looks a bit worse on one run

* Basic time/space performance vs SEQUEST/MM (Xtandem?)

* Can we choose a tolerance that has similar valid id's and (we hope) speed?!!


* Verify that our MM build is reading spectra correctly
* Need myrimatch-process for testing?

* Check in test suite/etc for complete release

* Generate a set of sample .conf files
** One long, commented template file?

* Write release email
** What it does and doesn't yet do
** How to use it



= M1 =========================================================================

* Try greylag-validate refinement

* Implement semi-tryptic cleavage
** Reputed to be almost as good as tryptic (valid peptide count)?

* Debian/Ubuntu package?

* greylag-validate parent tolerance analysis

* Add docstring for every function

* Need some greylag-merge test cases

* Basic optimization (just a quick further look for easy speedups)
** callgrind
** cachegrind

* Change the way mod limit works?  ({1,4} feature?)


* Update docstrings

* calculate Ion%?

* Further test case updates/adds
** enzymatic cleavage

* Use SHA1 digests to keep files in sync?

* Design and implement greylag master process (work manifests?)

* Why aren't scores a little more stable?  (fast-math?)

* Add A1S2D1C3A1S2D1F4 marking form for isotope regimes?

* Register copyright?




= M2 =========================================================================


* Maybe switch greylag-process to Python?

* Evaluate performance differences vs Xtandem?

* Try the MM smart +3 model--much improvement?

* Try the MM precursor mass adjustment--much improvement?  even a good idea?

* Test tolerance monotonicity

* summarize differences between greylag-validate and DBValidate (see paper)

* [HOLD/NOT A PROBLEM???] glw files too slow, too big, other problems
** maybe this is only a problem on small RAM machines?
** just use modified SQT files?  put metadata in special header lines?
*** greylag-merge, greylag-sqt become greylag-merge?
*** may still need separate metadata files...


* Add isotope jitter feature, for Orbitrap.

  xtandem considers one C13 if MH>1000, and one/two C13 if MH>1500.  Should we
  try to predict this based on the peptide sequence?  MH probably close
  enough.  What does MyriMatch do?


* Implement MyriMatch charge-calling algorithm?

* Implement MyriMatch deisotoping?


* Investigate identification differences between greylag and SEQUEST/MM.

* Clean up [,] (N/C-terminal) mass regime calculations

* Pass through the C++ code looking for counts that could conceivably overflow
** Fix or add assertions

* Add duplicate peptide masking optimization
** Problem: shuffled versions generally not identical.  Limits potential
   speedup to 25-30%
** This will obviate the need to detect identical best matches at search time?
** Fix redundant peptide reporting

* Make a tool to compare greylag vs SEQUEST results by spectrum.  Want gross
  statistics--how many id's are the same, different, missing, etc.  For each
  spectrum, want to see what each program did, and how many times the assigned
  locus was otherwise id'ed.

* PPM error tolerances (MyriMatch doesn't implement this?)

* Make --estimate work correctly over cluster.  (Currently takes 6 hours to
  estimate 60--is this worthwhile?  Could we simply estimate one bag and
  multiply by the number of bags??)

* Better shuffling than current model.

* Useful to scale fragment tolerance by charge, too?

* Have --estimate generate a spectrum work count file (*.est?) that can be
  used by --part-split to generate evenly sized parts.  (Check that file is
  newer than params file and ms2 file arguments, and that all ms2 file
  arguments were estimated.)

* Maybe --part-split should generate a downramp of sizes?  It definitely
  should take into account spectra filtered out (== no work), but this
  requires reading all spectra before splitting (which takes more time).

* Fix "cleavage C-terminal mass change" issue.  Should this be interpreted as
  MONO, ! (first fragment regime), or by regime.  Look for similar problems
  elsewhere.

* Make static '[' mod exclude PCA mods.

* Code cleanup, especially in new Python code.  Maybe put some stuff in
  classes.  Could split into multiple source files.

* Mine OMSSA and myrimatch for ideas.  Look again at X!Tandem and SEQUEST
  papers.

* Need tool to compare two runs, for regression testing purposes.

* Add refinement.  (like xtandem?)

* Advanced refinement ideas.  For example, only search a locus for a hit with N
  mods if we got a hit for it with 0..N-1 mods (or maybe 0..N-2?).  Or, only
  search a locus non-tryptically (or semi-tryptically) if we got a tryptic hit
  for it.

** Investigate current SEQUEST search results to see if this looks feasible.

* Think about ways to get more id's per hour of processing time.

* Try to adapt to instrument accuracy.  Maybe start with a narrow parent mass
  range and adaptively widen it.

* Profiling to find slow spots, and for correctness?

* Heavy optimization on inner loop.
** Try running from both ends simultaneously.
** Watch cache usage.

* Should we try to guarantee that searching is equivalent for all mass regimes,
  to make comparisons more valid?

* Rigorously check all values coming in from Python (at least by assert).

* We can now pre-build a peptide index if we want to.  The main utility of this
  is that it would allow us to avoid searching a spectrum against the same
  peptide multiple times (saving perhaps 30% runtime for one real database).
  Alternatively, maybe we could just generate a description of peptides to be
  masked out.

* Incrementalize the whole program.  Want to be able to take an existing run
  and spend more time on it to get more results, possibly concentrating on a
  particular kind of modification.

* Try to figure out whether SEQUEST is really searching everything, or whether
  it gives up in certain cases like X!Tandem does.

* Isotope S34 and C13 are common (4%, 1%).  Is there a good way to look for
  them?  We could look for singleton occurrences pretty cheaply using a delta
  mod type procedure.

* Splitting idea: Rather than having all parts be equal, maybe its better for
  the parts processed first to be bigger, with smallest parts processed last,
  so that they can fill in the final gaps (leading all processors to finish at
  about the same time).  What should the split curve look like?  Linear, but
  what slope?  No split should be smaller than one spectrum (after
  filtering).

* Possible generation optimization: Figure out the maximum number of mods,
  which would be the number that could be added to the smallest, lightest
  peptide without exceeding the mass of the largest spectrum parent mass.
  Probably not worth doing?  Similarly, if we know all bags of size N are too
  large, and all deltas are positive, we can skip larger bags.

* If we see a good hit for a spectrum, we could try to see if there's an
  identifiable tag.  If so, could restrict further searching to peptides with
  that tag.

* Could try switching FP code to use integers instead (but ugh)

* Is there anything we can do with neutral losses?

* Need a way to test spectrum synthesis?
