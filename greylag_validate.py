#!/usr/bin/env python

"""
Given a set of sqt files, determine a 'valid' set of identifications that
satisfy the specified FDR (false discovery rate) and other specified criteria.
Optionally rewrite the sqt files with invalid spectra marked 'N' or deleted
altogether.

Note that a peptide end with an invalid flanking residue (currently any of
BJOUXZ) is not considered tryptic if it's an N-terminal end and is considered
tryptic if it's a C-terminal end and otherwise qualifies.  (Flanking '-' is
always considered tryptic.)

"""

from __future__ import with_statement

__copyright__ = '''
    greylag, a collection of programs for MS/MS protein analysis
    Copyright (C) 2006-2008  Stowers Institute for Medical Research

    This program is free software: you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation, either version 3 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License
    along with this program.  If not, see <http://www.gnu.org/licenses/>.

    Contact: Mike Coleman
             Stowers Institute for Medical Research
             1000 East 50th Street
             Kansas City, Missouri  64110
             USA
'''


from collections import defaultdict
import itertools
import optparse
import os
from pprint import pprint
import re
import string
import sys
import time


# allow this script to be run even if not "installed"
try:
    from greylag import VERSION
except:
    VERSION = 'unknown'


def warn(s):
    print >> sys.stderr, 'warning:', s
def error(s):
    sys.exit('error: ' + s)


def generate_spectra_from_files(sqt_filenames):
    """Yield tuples (filename, H+_lines, S_line, [(M_line, mod_lines, L_lines),
    ...]) for the given SQT files.  H+_lines, for example, is a list
    containing H lines and possibly other kinds of lines up to the next S
    line.  (mod_lines are non-L lines following an M-line.)
    """
    for sqt_filename in sqt_filenames:
        with open(sqt_filename) as sqtf:
            sqt_filename = os.path.splitext(sqt_filename)[0]
            H_lines = []
            S_line, ML_lines = None, []
            for line in sqtf:
                if line.startswith('L\t'):
                    ML_lines[-1][2].append(line)
                elif line.startswith('M\t'):
                    ML_lines.append((line, [], []))
                elif line.startswith('S\t'):
                    if S_line:
                        yield (sqt_filename, H_lines, S_line, ML_lines)
                        S_line, ML_lines = None, []
                    S_line = line
                else:
                    if not S_line:
                        # read headers up to first S line
                        H_lines.append(line)
                    else:
                        # other kind of line following M line
                        ML_lines[-1][1].append(line)
            if S_line:
                yield (sqt_filename, H_lines, S_line, ML_lines)


def write_spectra_to_files(spectra):
    """Given a generator of tuples of the form generated by
    'generate_spectra_from_files', write them to the implied files.  If any of
    those files already exist, they are renamed with a '.bak' suffix.  Temp
    files are written first, then renamed at the end.
    """

    tmp_suffix = '.tmp.%s' % time.time()

    # filename -> file
    filemap = {}

    for sqt_filename, H_lines, S_line, ML_lines in spectra:
        sqtf = filemap.get(sqt_filename)
        if sqtf == None:
            sqtf = filemap[sqt_filename] = open(sqt_filename + tmp_suffix, 'w')
            for h in H_lines:
                sqtf.write(h)
        sqtf.write(S_line)
        for m_line, mod_lines, l_lines in ML_lines:
            sqtf.write(m_line)
            for m in mod_lines:
                sqtf.write(m)
            for l in l_lines:
                sqtf.write(l)

    for fd in filemap.values():
        fd.close()
    for fn in filemap:
        if os.path.exists(fn):
            os.rename(fn, fn + '.bak')
        os.rename(fn + tmp_suffix, fn)


def reset_marks(spectra):
    """Given a generator of tuples of the form generated by
    'generate_spectra_from_files', yield them with the M line marks
    (destructively) reset to U.
    """

    def reset_mark(m_line):
        return re.sub(r'\S(\s*)$', r'U\1', m_line, 1)

    for sqt_filename, H_lines, S_line, ML_lines in spectra:
        ML_lines_1 = [ (reset_mark(M_line), mod_lines, L_lines)
                       for M_line, mod_lines, L_lines in ML_lines ]
        yield (sqt_filename, H_lines, S_line, ML_lines_1)


def set_marks(options, valid_spectrum_info, spectra, kill=False):
    """Given a generator of tuples 'spectra' of the form generated by
    'generate_spectra_from_files', yield them with the M line marks
    (destructively) set to 'N', for spectra not listed in
    valid_spectrum_info.  If 'kill', omit marked spectra altogether.
    """

    def set_mark(m_line):
        return re.sub(r'\S(\s*)$', r'N\1', m_line, 1)

    passing_spectrum_numbers = frozenset(si[0] for si in valid_spectrum_info)

    for spectrum_no, (sqt_filename, H_lines, S_line, ML_lines) \
            in enumerate(spectra):
        mark_spectrum = spectrum_no not in passing_spectrum_numbers
        if mark_spectrum and not kill:
            ML_lines = [ (set_mark(M_line), mod_lines, L_lines)
                         for M_line, mod_lines, L_lines in ML_lines ]
        if not (kill and mark_spectrum):
            yield (sqt_filename, H_lines, S_line, ML_lines)


nulltrans = string.maketrans('','')
non_aa_chars = string.digits + string.punctuation

def strip_mods(s):
    """Given a peptide, return just the unmodified peptide seen."""
    # assuming no control chars present
    return s.translate(nulltrans, non_aa_chars)


def get_spectrum_info(decoy_prefix, minimum_trypticity, spectra):
    """Return a pair, the first a dict mapping each charge to a list of
    (score, delta, state), where state is 'real' or 'decoy', for all the
    spectra in sqt_fns, and the second a list of (charge, score, delta), one
    for each spectrum, given a generator of tuples 'spectra' of the form
    generated by 'generate_spectra_from_files'.  Spectra lacking
    minimum_trypticity are dropped.
    """

    ## charge -> [ (score, delta, state), ... ]
    ##   where state is either 'real' or 'decoy'
    #z_scores = defaultdict(list)

    ## information about spectra, in file order--None iff spectrum was filtered
    ## out
    ## [ (charge, score, delta) or None, ... ]
    #sp_scores = []

    # [ (spectrum_no, charge, score, delta, state, stripped_peptide), ... ]
    spectrum_info = []

    for spectrum_no, (sqt_filename,
                      H_lines, S_line, ML_lines) in enumerate(spectra):
        S_fields = S_line.split('\t')
        current_charge = int(S_fields[3])
        actual_mass = float(S_fields[6])
        spectrum_name = '.'.join([sqt_filename] + S_fields[1:4])

        current_score = None
        current_delta = None
        current_peptide_trypticity = None
        current_state = set()
        current_loci = set()
        highest_rank_seen = 0
        best_peptide_seen = None
        current_peptide = None

        for M_line, mod_lines, L_lines in ML_lines:
            M_fields = M_line.split('\t')

            rank = int(M_fields[1])
            predicted_mass = float(M_fields[3])
            score = float(M_fields[5])
            peptide = M_fields[9].strip().upper() # e.g., A.B@CD*.-
            #delta = float(M_fields[4])
            #sp_rank = int(M_fields[2])
            assert score >= 0 and rank >= 1

            if rank > highest_rank_seen + 1:
                # ignore aux top SpRank hits, because delta confounds
                break
            highest_rank_seen = rank

            if current_score == None:
                if score <= 0:
                    break               # spectrum is total crap
                current_score = score

            # Don't trust delta from input file.
            delta = (current_score - score) / current_score

            assert peptide[1] == '.' and peptide[-2] == '.'
            peptide_flanks = (peptide[0], peptide[-1]) # ('A', '-')
            peptide = peptide[2:-2]                    # 'B@CD*'

            if current_peptide == None:
                current_peptide = peptide
                current_peptide_trypticity = 0
                # NB: K*, R* not tryptic!
                if (peptide_flanks[0] in ('K', 'R') and peptide[0] != 'P'
                    or peptide_flanks[0] == '-'):
                    current_peptide_trypticity += 1
                if (peptide[-1] in ('K', 'R') and peptide_flanks[1] != 'P'
                    or peptide_flanks[1] == '-'):
                    current_peptide_trypticity += 1

            # Choose delta from first M line such that peptide differs from
            # peptide in initial (top) M line.  We consider differently
            # modified versions of the same peptide to be different (at least
            # for now).
            if peptide != current_peptide:
                current_delta = delta
                break

            for L_line in L_lines:
                locus = L_line.split('\t')[1]
                current_loci.add(locus)
                if locus.startswith(decoy_prefix):
                    current_state.add('decoy')
                else:
                    current_state.add('real')

        if (current_score != None and current_delta != None
            and current_peptide_trypticity >= minimum_trypticity):

            if len(current_state) == 2:
                current_state = 'both'
            else:
                assert len(current_state) == 1
                current_state = current_state.pop()

            spectrum_info.append((spectrum_no, spectrum_name, current_charge,
                                  current_score, current_delta, current_state,
                                  current_peptide,
                                  strip_mods(current_peptide),
                                  actual_mass, actual_mass-predicted_mass,
                                  frozenset(current_loci)))

    return spectrum_info


# General algorithm:
# - repeat, adjusting fdr upwards (or downwards?) to meet user goal
#     repeat until set of valid spectra converges:
#         - do pr filter of spectra
#             - if not first time, and no spectra filtered out, break
#         - separately for each charge, choose valid spectra to maximize real ids subject to FDR
#     - saturate (locally or completely)


def PPV(reals, decoys):
    """Returns the estimated Positive Predictive Value (== 1 - FDR), given
    counts of reals and decoys."""

    # We know that the decoys are false positives, and we estimate that an
    # equal number of the "reals" are actually false, too.
    false_positives = 2*decoys
    true_positives = reals - decoys

    if true_positives <= 0:
        return 0
    return float(true_positives) / (true_positives + false_positives)


def calculate_inner_threshold(fdr, charge, spinfo):
    ppv_goal = 1 - fdr

    spinfo = sorted(spinfo, key=lambda x: x[3])

    epsilon = +1e-6

    real_count = sum(1 for x in spinfo if x[5] == 'real')
    decoy_count = sum(1 for x in spinfo if x[5] == 'decoy')

    current_threshold = -1e100      # allow all spectra
    for n, sp in enumerate(spinfo):
        if real_count == 0:
            return (None, real_count, decoy_count) # give up

        ppv_est = PPV(real_count, decoy_count)
        if ppv_est >= ppv_goal:
            break
        if sp[5] == 'real':
            real_count -= 1
        elif sp[5] == 'decoy':
            decoy_count -= 1
        # set threshold just high enough to exclude this spectrum
        current_threshold = sp[3] + epsilon
    else:
        current_threshold = spinfo[-1][3] + epsilon # couldn't meet goal

    return (current_threshold, real_count, decoy_count)


def calculate_combined_thresholds(fdr, options, spectrum_info):
    """Find best score/delta thresholds for each charge."""

    ppv_goal = 1 - fdr

    # Rather than search every possible value of delta, we're only going to
    # "sample" at this granularity.  This cuts search time dramatically (and
    # makes it O(n) instead of O(n**2).  Extra precision wouldn't really be
    # useful in any case.
    SEARCH_GRANULARITY = 0.001

    # charge -> (score, delta, passing_reals, passing_decoys)
    thresholds = {}

    by_charge = lambda x: x[2]
    spectrum_info.sort(key=by_charge)
    for charge, spinfo in itertools.groupby(spectrum_info, key=by_charge):
        spinfo0 = sorted(spinfo, key=lambda x: x[4], reverse=True)

        last_value = None

        while spinfo0:
            this_value = spinfo0[-1][4] # current delta
            if (last_value == None
                or abs(this_value - last_value) >= SEARCH_GRANULARITY):

                # "inner" is score
                r = calculate_inner_threshold(fdr, charge, spinfo0)
                threshold, real_count, decoy_count = r
                if threshold != None:
                    if options.debug:
                        print '#', charge, threshold, this_value, \
                            real_count, decoy_count
                    if (charge not in thresholds
                        or real_count > thresholds[charge][2]):
                        thresholds[charge] = (threshold, this_value,
                                              real_count, decoy_count)
                last_value = this_value
            spinfo0.pop()

    return thresholds


def flatten(gen_of_gens):
    for gen in gen_of_gens:
        for item in gen:
            yield item


def redundancy_filter(options, spectrum_info):
    if options.minimum_spectra_per_locus < 2:
        return spectrum_info[:]

    # si = (spectrum_no, spectrum_name, charge, score, delta, state,
    #       peptide, stripped_peptide, actual_mass, mass_delta, loci)

    Rs = sorted(flatten(((locus, si) for locus in si[10])
                        for si in spectrum_info))

    result = set()
    for locus, locus_Rs in itertools.groupby(Rs, key=lambda x: x[0]):
        list_locus_si = [ si for locus, si in locus_Rs ]
        if len(list_locus_si) < options.minimum_spectra_per_locus:
            continue
        result |= set(list_locus_si)
    return sorted(result)


def saturate_by_prefix_suffix(spectrum_info, saturation_spectrum_info):
    PREFIX_LENGTH = 16          # empirically seems good
    peptide_prefixes = set(si[7][:PREFIX_LENGTH] for si in spectrum_info)
    sat_si = sorted(ssi for ssi in saturation_spectrum_info
                    if ssi[7][:PREFIX_LENGTH] in peptide_prefixes)

    print ("saturation by prefix (w/%s): %s -> %s"
           % (len(saturation_spectrum_info), len(spectrum_info), len(sat_si)))
    return sat_si


def saturate(spectrum_info, saturation_spectrum_info):
    peptides = set(si[7] for si in spectrum_info)
    # FIX: does this actually need to be sorted?
    sat_si = sorted(ssi for ssi in saturation_spectrum_info
                    if ssi[7] in peptides)
    print ("saturation (w/%s): %s -> %s"
           % (len(saturation_spectrum_info), len(spectrum_info), len(sat_si)))
    return saturate_by_prefix_suffix(sat_si, saturation_spectrum_info)
    #return sat_si


def debug_fdr(si):
    print len(si), sum(1 for x in si if x[5] == 'real'), sum(1 for x in si if x[5] == 'decoy')


def try_fdr(fdr_guess, options, remaining_spectrum_info, saturation_spectrum_info=None):
    print "try_fdr:", fdr_guess
    debug_fdr(remaining_spectrum_info)

    remaining_spectrum_info_1 = None
    while True:
        thresholds = calculate_combined_thresholds(fdr_guess, options,
                                                   remaining_spectrum_info)
        remaining_spectrum_info = [ si for si in remaining_spectrum_info
                                    if (si[2] in thresholds
                                        and si[3] >= thresholds[si[2]][0]
                                        and si[4] >= thresholds[si[2]][1]) ]
        debug_fdr(remaining_spectrum_info)
        if remaining_spectrum_info == remaining_spectrum_info_1:
            break
        remaining_spectrum_info_1 = redundancy_filter(options,
                                                      remaining_spectrum_info)
        debug_fdr(remaining_spectrum_info_1)
        if len(remaining_spectrum_info_1) == len(remaining_spectrum_info):
            break
        remaining_spectrum_info = remaining_spectrum_info_1

    if not options.no_saturation and saturation_spectrum_info:
        remaining_spectrum_info_1 = saturate(remaining_spectrum_info_1,
                                             saturation_spectrum_info)
        debug_fdr(remaining_spectrum_info_1)

    total_reals = sum(1 for si in remaining_spectrum_info_1
                      if si[5] == 'real')
    total_decoys = sum(1 for si in remaining_spectrum_info_1
                       if si[5] == 'decoy')
    #total_reals = sum(thresholds[charge][2] for charge in thresholds)
    #total_decoys = sum(thresholds[charge][3] for charge in thresholds)
    fdr_result = 1 - PPV(total_reals, total_decoys)

    return (fdr_result, thresholds, total_reals, total_decoys,
            remaining_spectrum_info_1)


# FIX: at various points here we may have a goal of a minimum number of real
# ids, based on goal FDR or whatever.  We can pass this inward to do
# branch-and-bound, which may save time.

# FIX: this is now somewhat slower than before--any way to speed it up?

def search_adjusting_fdr(options, spectrum_info_0):
    """Repeatedly calculate thresholds while adjusting FDR, looking for an FDR
    guess that results in an appropriate goal FDR.  This might be needed
    because the thresholds found for per-charge FDRs will be saturated or have
    quantization errors, resulting in overly conservative thresholds.  Returns
    a list of items from spectrum_info that are considered "valid".
    """

    # FIX: Does this generate enough additional real ids to be worth the
    # computational cost?
    #FDR_INFLATION_FACTOR = 1.1
    FDR_INFLATION_FACTOR = 3
    assert FDR_INFLATION_FACTOR > 1

    spectrum_info = redundancy_filter(options, spectrum_info_0)

    low_fdr = options.fdr
    # FIX: spectrum_info_0 has already been filtered for tryptic status
    # Should we use an unfiltered set instead?
    low_results = try_fdr(low_fdr, options, spectrum_info, spectrum_info_0)

    if options.adjust_fdr:
        high_fdr = min(1.0, options.fdr * FDR_INFLATION_FACTOR)
        high_results = try_fdr(high_fdr, options, spectrum_info,
                               spectrum_info_0)
        initial_total_reals = low_results[2]

        for i in range(32):
            if options.debug:
                print ("adjust infl fdr %s %s -> %s"
                       % (low_fdr, high_fdr, high_results[0]))
            if high_results[0] >= options.fdr:
                break
            low_fdr, low_results = high_fdr, high_results
            high_fdr = min(1.0, high_fdr * FDR_INFLATION_FACTOR)
            if high_fdr == 1.0:
                break
            high_results = try_fdr(high_fdr, options, spectrum_info,
                                   spectrum_info_0)
        else:
            warn("FDR adjustment inflation failed")

        #    #
        #    l        g            h
        #   l       g         h
        #    #

        CONVERGENCE_FACTOR = 0.01
        assert CONVERGENCE_FACTOR > 0
        for i in range(32):
            assert high_fdr >= low_fdr
            if (high_fdr - low_fdr) <= CONVERGENCE_FACTOR*options.fdr:
                break

            # - seems to be slower than the naive method?
            # Bias is empirically determined.  It's supposed to speed
            # convergence, but should not affect the results.
            # FIX: better method possible?
            #GUESS_BIAS = 1.15
            #prop = ((options.fdr - low_results[0])
            #        / (high_results[0] - low_results[0]))
            #prop = min(1, max(0, prop))
            #guess_fdr = low_fdr + prop**GUESS_BIAS * (high_fdr - low_fdr)

            ####
            guess_fdr = (high_fdr + low_fdr) / 2.0

            guess_results = try_fdr(guess_fdr, options, spectrum_info,
                                    spectrum_info_0)
            if options.debug:
                print ("adjust fdr %s %s %s -> %s"
                       % (low_fdr, guess_fdr, high_fdr, guess_results[0]))
            if guess_results[0] > options.fdr:
                high_fdr, high_results = guess_fdr, guess_results
            else:
                low_fdr, low_results = guess_fdr, guess_results
        else:
            warn("FDR adjustment convergence failed")

    (fdr_result, thresholds, total_reals,
     total_decoys, valid_spectrum_info) = low_results

    if options.output_peptides:
        valid_spectrum_info.sort(key=lambda x: x[1])
        for (spectrum_no, spectrum_name, charge, score, delta, state,
             peptide, stripped_peptide, actual_mass,
             mass_delta, loci) in valid_spectrum_info:
            print >> options.output_peptides, \
                ("%+d %s %s %s %.8f %.8f"
                 % (charge, spectrum_name, state, peptide, actual_mass,
                    mass_delta))

    for charge in sorted(thresholds.keys()):
        score_threshold, delta_threshold = thresholds[charge][0:2]
        reals, decoys = thresholds[charge][2:4]
        print ("%+d: score %f, delta %.6f -> %s real ids, %s decoys"
               " (fdr %.4f)"
               % (charge, score_threshold, delta_threshold,
                  reals, decoys, 0.5 * (1 - PPV(reals, decoys))))
    print ("# total: %s real ids, %s decoys (fdr %.4f)"
           % (total_reals, total_decoys, fdr_result / 2.0))
    if options.adjust_fdr:
        print ("# (FDR adjustment found %s more real ids)"
               % (total_reals - initial_total_reals))

    return valid_spectrum_info


def main(args=sys.argv[1:]):
    parser = optparse.OptionParser(usage=
                                   "usage: %prog [options] <sqt-file>...",
                                   description=__doc__, version=VERSION)
    pa = parser.add_option
    DEFAULT_DECOY_PREFIX = "SHUFFLED_"
    pa("--decoy-prefix", dest="decoy_prefix", default=DEFAULT_DECOY_PREFIX,
       help='prefix given to locus name of decoy (e.g., shuffled) database'
       ' sequences [default=%r]' % DEFAULT_DECOY_PREFIX, metavar="PREFIX")
    DEFAULT_FDR = 0.01
    pa("--fdr", dest="fdr", type="float", default=DEFAULT_FDR,
       help="false discovery rate [default=%s] (Note that this is the"
       " final resulting FDR after the decoys have been removed" % DEFAULT_FDR,
       metavar="PROPORTION")
    pa("--adjust-fdr", action="store_true", dest="adjust_fdr",
       help="try to adjust internal FDR to achieve a final FDR closer to"
       " requested FDR (this takes longer, but may find more read ids in some"
       " cases)")
    pa("--no-saturation", action="store_true", dest="no_saturation",
       help="skip peptide saturation")
    pa("-v", "--verbose", action="store_true", dest="verbose",
       help="be verbose")
    pa("--output-peptides", dest="output_peptides",
       help="output information about passing peptides to specified file"
       " ('-' for stdout)", metavar="FILENAME")
    pa("-t", "--minimum-trypticity", type="choice", choices=('0', '1', '2'),
       default='0', dest="minimum_trypticity",
       help="drop peptides with too few tryptic ends"
       " (2=fully tryptic, 1=semi-tryptic, 0=any)", metavar="TRYPTICITY")
    DEFAULT_MINIMUM_SPECTRA_PER_LOCUS = 1
    pa("-p", "--minimum-spectra-per-locus", dest="minimum_spectra_per_locus",
       type="int", default=DEFAULT_MINIMUM_SPECTRA_PER_LOCUS,
       help="only loci with at least this many spectra are included, and"
       " spectra not associated with such a locus are excluded"
       " [default=%s]" % DEFAULT_MINIMUM_SPECTRA_PER_LOCUS,
       metavar="COUNT")
    #pa("--graph", dest="graph",
    #   help='create distribution graphs, using the specified prefix',
    #   metavar="PATH PREFIX")
    pa("--debug", action="store_true", dest="debug",
       help="show debug output")
    pa("--mark", action="store_true", dest="mark",
       help="rewrite the input files, changing some validation marks to 'N',"
       " according to filtering")
    pa("--reset-marks", action="store_true", dest="reset_marks",
       help="rewrite the input files, changing all validation marks to 'U'")
    pa("--kill", action="store_true", dest="kill",
       help="rewrite the input files, removing spectra that don't pass"
       " validation, according to filtering")
    pa("--copyright", action="store_true", dest="copyright",
       help="print copyright and exit")
    (options, args) = parser.parse_args(args=args)

    if options.copyright:
        print __copyright__
        sys.exit(0)

    if len(args) < 1 or options.minimum_spectra_per_locus < 0:
        parser.print_help()
        sys.exit(1)

    if not (0.0 <= options.fdr < 0.5):
        error("--fdr must be within range [0.0, 0.5)")
    if (sum(1 for x in (options.mark, options.reset_marks, options.kill) if x)
        > 1):
        error("only one of --mark, --reset-marks, --kill may be specified")

    if options.reset_marks:
        write_spectra_to_files(reset_marks(generate_spectra_from_files(args)))
        return

    if options.output_peptides:
        if options.output_peptides == '-':
            options.output_peptides = sys.stdout
        else:
            options.output_peptides = open(options.output_peptides, 'w')

    # This is to translate the "effective" FDR, which is the rate after decoys
    # have been stripped out of the results (which is what users really care
    # about), into our internal FDR, which includes decoys.
    options.fdr *= 2

    spectrum_info = get_spectrum_info(options.decoy_prefix,
                                      int(options.minimum_trypticity),
                                      generate_spectra_from_files(args))

    if options.debug:
        print ('%s passing spectra, of which %s are not decoys'
               % (len(spectrum_info),
                  sum(1 for si in spectrum_info if si[5] == 'real')))

    # valid_spectrum_info is the list of spectrum_info elements that have been
    # chosen as "valid"
    valid_spectrum_info = search_adjusting_fdr(options, spectrum_info)

    if options.debug:
        valid_spectrum_info.sort()
        for (spectrum_no, spectrum_name, charge, score, delta, state,
             peptide, stripped_peptide, actual_mass,
             mass_delta, loci) in valid_spectrum_info:
            print '#S', charge, score, delta

    if options.mark or options.kill:
        # Note that we are intentionally reading the input files again here,
        # to avoid having to keep them all in memory.
        write_spectra_to_files(set_marks(options, valid_spectrum_info,
                                         generate_spectra_from_files(args),
                                         options.kill))


if __name__ == '__main__':
    main()
